{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, classification_report, roc_curve)\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, BaggingClassifier, \n",
    "                              GradientBoostingClassifier, AdaBoostClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a random seed and creat a synthetic dataset (of 20,000) with the features provided in the project description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_records = 20000\n",
    "\n",
    "#Gernerate data for each feature\n",
    "data = {\n",
    "    \"Age\": np.random.randint(18,65,size=n_records),\n",
    "    \"Gender\": np.random.choice([\"Male\",\"Female\"],size=n_records),\n",
    "    \"Marital_Status\": np.random.choice([\"Single\",\"Married\",\"Divorced\"], size=n_records),\n",
    "    \"Education_Level\": np.random.choice([\"High School\", \"Bachelor\",\"Master\",\"PhD\"], size=n_records),\n",
    "    \"Job_Role\": np.random.choice([\"Sales Executive\", \"Research Scientist\", \"Manager\"], size=n_records),\n",
    "    \"Department\": np.random.choice([\"Sales\",\"Marketing\",\"HR\",\"IT\"], size=n_records),\n",
    "\n",
    "    \"Job_Satisfaction\": np.random.randint(1,6, size=n_records),\n",
    "    \"Work_Life_Balance\": np.random.randint(1,6,size=n_records),\n",
    "    \"Number_Of_Companies_Worked\": np.random.randint(1,10, size=n_records),\n",
    "    \"Distance_From_Home\": np.random.uniform(1,50, size=n_records).round(2),\n",
    "    \"Overtime\": np.random.choice([\"Yes\",\"No\"],size=n_records),\n",
    "    \"Job_Involvement\":np.random.randint(1,6, size=n_records),\n",
    "\n",
    "    \"Salary\": np.random.uniform(30000, 150000, size=n_records),\n",
    "    \"Hourly_Rate\": np.random.uniform(15,100, size=n_records).round(2),\n",
    "    \"Stock_Option_Level\": np.random.randint(0,5, size=n_records),\n",
    "    \"Bonuses\": np.random.choice([\"Yes\",\"No\"], size=n_records),\n",
    "\n",
    "    \"Years_At_Company\": np.random.randint(0,40, size=n_records),\n",
    "    \"Training_Times_Last_Year\": np.random.randint(0,10,size=n_records),\n",
    "    \"Job_Level\": np.random.randint(1,6, size=n_records),\n",
    "    \"Employee_Recognition\": np.random.choice([\"Yes\", \"No\"], size=n_records),\n",
    "\n",
    "    \"Performance_Rating\": np.random.randint(1,6, size=n_records),\n",
    "    \"Absenteeism\": np.random.randint(0,20, size=n_records),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Job_Role</th>\n",
       "      <th>Department</th>\n",
       "      <th>Job_Satisfaction</th>\n",
       "      <th>Work_Life_Balance</th>\n",
       "      <th>Number_Of_Companies_Worked</th>\n",
       "      <th>Distance_From_Home</th>\n",
       "      <th>...</th>\n",
       "      <th>Hourly_Rate</th>\n",
       "      <th>Stock_Option_Level</th>\n",
       "      <th>Bonuses</th>\n",
       "      <th>Years_At_Company</th>\n",
       "      <th>Training_Times_Last_Year</th>\n",
       "      <th>Job_Level</th>\n",
       "      <th>Employee_Recognition</th>\n",
       "      <th>Performance_Rating</th>\n",
       "      <th>Absenteeism</th>\n",
       "      <th>Attrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Master</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>24.32</td>\n",
       "      <td>...</td>\n",
       "      <td>37.95</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Master</td>\n",
       "      <td>Manager</td>\n",
       "      <td>HR</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.74</td>\n",
       "      <td>...</td>\n",
       "      <td>52.35</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>Master</td>\n",
       "      <td>Manager</td>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>22.91</td>\n",
       "      <td>...</td>\n",
       "      <td>37.21</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Master</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>Sales</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>39.29</td>\n",
       "      <td>...</td>\n",
       "      <td>93.75</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>HR</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>31.32</td>\n",
       "      <td>...</td>\n",
       "      <td>27.63</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender Marital_Status Education_Level            Job_Role Department  \\\n",
       "0   56    Male        Married          Master  Research Scientist         IT   \n",
       "1   46    Male       Divorced          Master             Manager         HR   \n",
       "2   32    Male        Married          Master             Manager         IT   \n",
       "3   60  Female       Divorced          Master     Sales Executive      Sales   \n",
       "4   25    Male       Divorced        Bachelor     Sales Executive         HR   \n",
       "\n",
       "   Job_Satisfaction  Work_Life_Balance  Number_Of_Companies_Worked  \\\n",
       "0                 2                  3                           3   \n",
       "1                 4                  2                           1   \n",
       "2                 2                  2                           8   \n",
       "3                 4                  1                           7   \n",
       "4                 1                  4                           3   \n",
       "\n",
       "   Distance_From_Home  ... Hourly_Rate  Stock_Option_Level  Bonuses  \\\n",
       "0               24.32  ...       37.95                   4      Yes   \n",
       "1               26.74  ...       52.35                   2      Yes   \n",
       "2               22.91  ...       37.21                   1      Yes   \n",
       "3               39.29  ...       93.75                   0       No   \n",
       "4               31.32  ...       27.63                   3      Yes   \n",
       "\n",
       "   Years_At_Company  Training_Times_Last_Year Job_Level  Employee_Recognition  \\\n",
       "0                31                         1         2                    No   \n",
       "1                28                         4         2                   Yes   \n",
       "2                25                         1         1                   Yes   \n",
       "3                28                         2         2                   Yes   \n",
       "4                 9                         3         3                    No   \n",
       "\n",
       "   Performance_Rating  Absenteeism Attrition  \n",
       "0                   3           12         0  \n",
       "1                   1           17         0  \n",
       "2                   3            2         0  \n",
       "3                   5            9         0  \n",
       "4                   1           14         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creat the DataFram\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Generate the target variables with calss imbalance of 10% attrition rate\n",
    "df[\"Attrition\"] = np.where(np.random.rand(n_records) < 0.1,1,0)\n",
    "\n",
    "#Display the first few rows\n",
    "rows, cols = df.shape\n",
    "print(f\"Number of Rows: {rows}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                           0\n",
      "Gender                        0\n",
      "Marital_Status                0\n",
      "Education_Level               0\n",
      "Job_Role                      0\n",
      "Department                    0\n",
      "Job_Satisfaction              0\n",
      "Work_Life_Balance             0\n",
      "Number_Of_Companies_Worked    0\n",
      "Distance_From_Home            0\n",
      "Overtime                      0\n",
      "Job_Involvement               0\n",
      "Salary                        0\n",
      "Hourly_Rate                   0\n",
      "Stock_Option_Level            0\n",
      "Bonuses                       0\n",
      "Years_At_Company              0\n",
      "Training_Times_Last_Year      0\n",
      "Job_Level                     0\n",
      "Employee_Recognition          0\n",
      "Performance_Rating            0\n",
      "Absenteeism                   0\n",
      "Attrition                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill numerical columns with median\n",
    "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "#Fill categorical columns with mode\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode all categorical columns\n",
    "df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify numerical columns (excluding the target variable)\n",
    "num_cols = [col for col in df_encoded.columns if df_encoded[col].dtype in [\"int64\", \"float64\"] and col != \"Attrition\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_encoded[num_cols] = scaler.fit_transform(df_encoded[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat Models and compare the performance using three different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features and target\n",
    "X = df_encoded.drop(\"Attrition\", axis=1)\n",
    "y = df_encoded[\"Attrition\"]\n",
    "\n",
    "#Split data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate the ratio of negative to positive calsses in y_train\n",
    "counter = Counter(y_train)\n",
    "scale_pos_weight = counter[0] / counter[1]\n",
    "\n",
    "#Initialize models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, class_weight={0:1, 1:10}),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric = \"logloss\", random_state=42, scale_pos_weight=scale_pos_weight)\n",
    "}\n",
    "\n",
    "# Function to evaluate and print model performance\n",
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    print(f\"----- {name} -----\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "    if y_pred_prob is not None:\n",
    "        print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_prob))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1296 candidates, totalling 3888 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:38:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for XGBoost: {'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'scale_pos_weight': 8.467455621301776, 'subsample': 0.8}\n",
      "Training Random Forest with SMOTE resampled data...\n",
      "----- Random Forest -----\n",
      "Accuracy: 0.858\n",
      "Precision: 0.10526315789473684\n",
      "Recall: 0.04784688995215311\n",
      "F1 Score: 0.06578947368421052\n",
      "ROC-AUC: 0.5062727246012092\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      3582\n",
      "           1       0.11      0.05      0.07       418\n",
      "\n",
      "    accuracy                           0.86      4000\n",
      "   macro avg       0.50      0.50      0.49      4000\n",
      "weighted avg       0.81      0.86      0.83      4000\n",
      "\n",
      "\n",
      "\n",
      "Training Gradient Boosting with SMOTE resampled data...\n",
      "----- Gradient Boosting -----\n",
      "Accuracy: 0.845\n",
      "Precision: 0.0860655737704918\n",
      "Recall: 0.050239234449760764\n",
      "F1 Score: 0.0634441087613293\n",
      "ROC-AUC: 0.5216533224335393\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      3582\n",
      "           1       0.09      0.05      0.06       418\n",
      "\n",
      "    accuracy                           0.84      4000\n",
      "   macro avg       0.49      0.49      0.49      4000\n",
      "weighted avg       0.81      0.84      0.83      4000\n",
      "\n",
      "\n",
      "\n",
      "Training XGBoost with SMOTE resampled data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:38:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- XGBoost -----\n",
      "Accuracy: 0.78875\n",
      "Precision: 0.09177820267686425\n",
      "Recall: 0.11483253588516747\n",
      "F1 Score: 0.10201912858660998\n",
      "ROC-AUC: 0.4988418968847427\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      3582\n",
      "           1       0.09      0.11      0.10       418\n",
      "\n",
      "    accuracy                           0.79      4000\n",
      "   macro avg       0.49      0.49      0.49      4000\n",
      "weighted avg       0.81      0.79      0.80      4000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resample training data using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define a parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0, 0.1, 0.5],\n",
    "    'scale_pos_weight': [scale_pos_weight, scale_pos_weight * 2]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring='f1', cv=3, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Best parameters for XGBoost:\", grid_search.best_params_)\n",
    "\n",
    "# Replace the XGBoost model in our models dictionary with the tuned estimator\n",
    "models[\"XGBoost\"] = grid_search.best_estimator_\n",
    "\n",
    "# Now train your models with the resampled data\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} with SMOTE resampled data...\")\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    evaluate_model(name, model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "----- Random Forest -----\n",
      "Accuracy: 0.8955\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "ROC-AUC: 0.492635292357588\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      3582\n",
      "           1       0.00      0.00      0.00       418\n",
      "\n",
      "    accuracy                           0.90      4000\n",
      "   macro avg       0.45      0.50      0.47      4000\n",
      "weighted avg       0.80      0.90      0.85      4000\n",
      "\n",
      "\n",
      "\n",
      "Training Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosting -----\n",
      "Accuracy: 0.8955\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "ROC-AUC: 0.5315840232528939\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      3582\n",
      "           1       0.00      0.00      0.00       418\n",
      "\n",
      "    accuracy                           0.90      4000\n",
      "   macro avg       0.45      0.50      0.47      4000\n",
      "weighted avg       0.80      0.90      0.85      4000\n",
      "\n",
      "\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:38:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- XGBoost -----\n",
      "Accuracy: 0.8705\n",
      "Precision: 0.08333333333333333\n",
      "Recall: 0.023923444976076555\n",
      "F1 Score: 0.03717472118959108\n",
      "ROC-AUC: 0.49795695649967003\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      3582\n",
      "           1       0.08      0.02      0.04       418\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.49      0.50      0.48      4000\n",
      "weighted avg       0.81      0.87      0.84      4000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train each model and evaluate\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_model(name, model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Prediction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Employee Data:\n",
      "{'Age': 62, 'Gender': 'Female', 'Marital_Status': 'Married', 'Education_Level': 'PhD', 'Job_Role': 'Sales Executive', 'Department': 'HR', 'Job_Satisfaction': 2, 'Work_Life_Balance': 4, 'Number_Of_Companies_Worked': 6, 'Distance_From_Home': 38.17, 'Overtime': 'Yes', 'Job_Involvement': 3, 'Salary': 120627.77266076641, 'Hourly_Rate': 46.2, 'Stock_Option_Level': 4, 'Bonuses': 'No', 'Years_At_Company': 9, 'Training_Times_Last_Year': 1, 'Job_Level': 1, 'Employee_Recognition': 'Yes', 'Performance_Rating': 1, 'Absenteeism': 10}\n",
      "Actual Attrition: Stay\n",
      "\n",
      "Prediction for random employee: Stay\n",
      "Probability of leaving: 0.01\n",
      "Model Confidence: 98.95%\n",
      "Prediction is correct.\n"
     ]
    }
   ],
   "source": [
    "expected_cols = X.columns\n",
    "\n",
    "def prepare_sample(sample_dict, expected_cols):\n",
    "    df_sample = pd.DataFrame([sample_dict])\n",
    "    for col in expected_cols:\n",
    "        if col not in df_sample.columns:\n",
    "            df_sample[col] = np.nan\n",
    "    df_sample = df_sample[expected_cols]\n",
    "    return df_sample\n",
    "\n",
    "def predict_employee_attrition(employee_features, model, scaler, expected_cols, cat_cols, num_cols):\n",
    "    df_sample = pd.DataFrame([employee_features])\n",
    "    df_sample_encoded = pd.get_dummies(df_sample, columns=cat_cols, drop_first=True)\n",
    "    df_sample_encoded = df_sample_encoded.reindex(columns=expected_cols, fill_value=0)\n",
    "    df_sample_encoded[num_cols] = scaler.transform(df_sample_encoded[num_cols])\n",
    "    prediction = model.predict(df_sample_encoded)\n",
    "    prediction_prob = model.predict_proba(df_sample_encoded)[:, 1]\n",
    "    return int(prediction[0]), float(prediction_prob[0])\n",
    "\n",
    "# Pull a random employee from the original data and predict\n",
    "random_index = np.random.choice(df.index)\n",
    "random_employee = df.loc[random_index].to_dict()\n",
    "actual_attrition = random_employee.pop(\"Attrition\")\n",
    "print(\"Random Employee Data:\")\n",
    "print(random_employee)\n",
    "print(\"Actual Attrition:\", \"Leave\" if actual_attrition == 1 else \"Stay\")\n",
    "\n",
    "prediction, probability = predict_employee_attrition(random_employee, models[\"XGBoost\"], scaler, X.columns, cat_cols, num_cols)\n",
    "result = \"Leave\" if prediction == 1 else \"Stay\"\n",
    "print(\"\\nPrediction for random employee:\", result)\n",
    "print(\"Probability of leaving: {:.2f}\".format(probability))\n",
    "confidence = probability if probability >= 0.5 else 1 - probability\n",
    "print(\"Model Confidence: {:.2f}%\".format(confidence * 100))\n",
    "print(\"Prediction is\", \"correct.\" if prediction == actual_attrition else \"incorrect.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
