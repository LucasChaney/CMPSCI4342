{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Impurity Measures for 'Survived':\n",
      "Overall Gini: 0.46875\n",
      "Overall Entropy: 0.95443\n",
      "\n",
      "Impurity Measures for each feature split:\n",
      "\n",
      "Feature: Pclass\n",
      "  Weighted Gini: 0.35417  |  Info Gain (Gini): 0.11458\n",
      "  Weighted Entropy: 0.75000  |  Info Gain (Entropy): 0.20443\n",
      "\n",
      "Feature: Sex\n",
      "  Weighted Gini: 0.30000  |  Info Gain (Gini): 0.16875\n",
      "  Weighted Entropy: 0.60684  |  Info Gain (Entropy): 0.34759\n",
      "\n",
      "Feature: Age\n",
      "  Weighted Gini: 0.00000  |  Info Gain (Gini): 0.46875\n",
      "  Weighted Entropy: 0.00000  |  Info Gain (Entropy): 0.95443\n",
      "\n",
      "Feature: SibSp\n",
      "  Weighted Gini: 0.43750  |  Info Gain (Gini): 0.03125\n",
      "  Weighted Entropy: 0.90564  |  Info Gain (Entropy): 0.04879\n",
      "\n",
      "Feature: Parch\n",
      "  Weighted Gini: 0.46875  |  Info Gain (Gini): 0.00000\n",
      "  Weighted Entropy: 0.95443  |  Info Gain (Entropy): 0.00000\n",
      "\n",
      "Feature: Fare\n",
      "  Weighted Gini: 0.12500  |  Info Gain (Gini): 0.34375\n",
      "  Weighted Entropy: 0.25000  |  Info Gain (Entropy): 0.70443\n",
      "\n",
      "Feature: Embarked\n",
      "  Weighted Gini: 0.00000  |  Info Gain (Gini): 0.46875\n",
      "  Weighted Entropy: 0.00000  |  Info Gain (Entropy): 0.95443\n",
      "\n",
      "Best Feature to split on (based on highest Info Gain from Entropy): Age\n",
      "         Weighted Gini Info Gain (Gini) Weighted Entropy Info Gain (Entropy)  \\\n",
      "Pclass        0.354167         0.114583             0.75            0.204434   \n",
      "Sex                0.3          0.16875         0.606844             0.34759   \n",
      "Age                0.0          0.46875              0.0            0.954434   \n",
      "SibSp           0.4375          0.03125         0.905639            0.048795   \n",
      "Parch          0.46875              0.0         0.954434                 0.0   \n",
      "Fare             0.125          0.34375             0.25            0.704434   \n",
      "Embarked           0.0          0.46875              0.0            0.954434   \n",
      "\n",
      "                                               Details Gini  \\\n",
      "Pclass    {1: (3, 0.4444444444444444, 0.375), 2: (1, 0.0...   \n",
      "Sex       {'female': (5, 0.48, 0.625), 'male': (3, 0.0, ...   \n",
      "Age       {22: (1, 0.0, 0.125), 23: (1, 0.0, 0.125), 26:...   \n",
      "SibSp                {0: (4, 0.375, 0.5), 1: (4, 0.5, 0.5)}   \n",
      "Parch                                {0: (8, 0.46875, 1.0)}   \n",
      "Fare      {7.93: (1, 0.0, 0.125), 8.05: (2, 0.5, 0.25), ...   \n",
      "Embarked  {'C': (2, 0.0, 0.25), 'Q': (1, 0.0, 0.125), 'S...   \n",
      "\n",
      "                                            Details Entropy  \n",
      "Pclass    {1: (3, 0.9182958340544896, 0.375), 2: (1, -0....  \n",
      "Sex       {'female': (5, 0.9709505944546686, 0.625), 'ma...  \n",
      "Age       {22: (1, -0.0, 0.125), 23: (1, -0.0, 0.125), 2...  \n",
      "SibSp     {0: (4, 0.8112781244591328, 0.5), 1: (4, 1.0, ...  \n",
      "Parch                      {0: (8, 0.954434002924965, 1.0)}  \n",
      "Fare      {7.93: (1, -0.0, 0.125), 8.05: (2, 1.0, 0.25),...  \n",
      "Embarked  {'C': (2, -0.0, 0.25), 'Q': (1, -0.0, 0.125), ...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the extended 8-row Titanic subset with all features.\n",
    "data = {\n",
    "    'PassengerId': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'Pclass':      [3, 1, 3, 1, 3, 1, 2, 3],\n",
    "    'Name':        [\"Name1\", \"Name2\", \"Name3\", \"Name4\", \"Name5\", \"Name6\", \"Name7\", \"Name8\"],\n",
    "    'Sex':         ['male', 'male', 'female', 'female', 'female', 'male', 'female', 'female'],\n",
    "    'Age':         [35, 22, 39, 30, 26, 54, 60, 23],\n",
    "    'SibSp':       [0, 1, 1, 1, 0, 0, 1, 0],\n",
    "    'Parch':       [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'Ticket':      [113803, 113051, 330923, 113503, 3101298, 17453, 237736, 330923],\n",
    "    'Fare':        [53.10, 26.55, 8.05, 211.50, 7.93, 51.86, 66.60, 8.05],\n",
    "    'Cabin':       [None, 'C22', None, 'C62', None, 'E46', None, None],\n",
    "    'Embarked':    ['S', 'S', 'S', 'C', 'S', 'S', 'C', 'Q'],\n",
    "    'Survived':    [0, 0, 0, 1, 0, 0, 1, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Computes Gini, Entropy, and Information Gain\n",
    "def compute_gini(series):\n",
    "    \"\"\"Compute Gini impurity for a binary series.\"\"\"\n",
    "    p1 = series.mean()  # proportion of ones in a binary column\n",
    "    p0 = 1 - p1\n",
    "    return 1 - (p0**2 + p1**2)\n",
    "\n",
    "def compute_entropy(series):\n",
    "    \"\"\"Compute entropy for a binary series.\"\"\"\n",
    "    p1 = series.mean()\n",
    "    p0 = 1 - p1\n",
    "    def safe_log2(x):\n",
    "        return np.log2(x) if x > 0 else 0\n",
    "    return - (p0 * safe_log2(p0) + p1 * safe_log2(p1))\n",
    "\n",
    "# Calculate overall impurity measures on the entire dataset for the target 'Survived'\n",
    "overall_gini = compute_gini(df['Survived'])\n",
    "overall_entropy = compute_entropy(df['Survived'])\n",
    "\n",
    "print(\"Overall Impurity Measures for 'Survived':\")\n",
    "print(f\"Overall Gini: {overall_gini:.5f}\")\n",
    "print(f\"Overall Entropy: {overall_entropy:.5f}\\n\")\n",
    "\n",
    "# Computes weighted impurity after splitting on a given feature.\n",
    "def weighted_impurity(df, feature, target='Survived', metric='gini'):\n",
    "    total = len(df)\n",
    "    weighted_value = 0.0\n",
    "    details = {}  # for debugging details per group\n",
    "    for value, group in df.groupby(feature):\n",
    "        n = len(group)\n",
    "        if metric == 'gini':\n",
    "            impurity = compute_gini(group[target])\n",
    "        else:\n",
    "            impurity = compute_entropy(group[target])\n",
    "        weight = n / total\n",
    "        weighted_value += weight * impurity\n",
    "        details[value] = (n, impurity, weight)\n",
    "    return weighted_value, details\n",
    "\n",
    "# List the features we want to evaluate for splitting.\n",
    "# Exclude features that are not useful for classification (e.g., PassengerId, Name, Ticket, Cabin)\n",
    "features_to_evaluate = [col for col in df.columns if col not in ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived']]\n",
    "\n",
    "# Loop over each feature and compute the impurity measures\n",
    "print(\"Impurity Measures for each feature split:\\n\")\n",
    "results = {}\n",
    "\n",
    "for feature in features_to_evaluate:\n",
    "    wgini, details_gini = weighted_impurity(df, feature, metric='gini')\n",
    "    wentropy, details_entropy = weighted_impurity(df, feature, metric='entropy')\n",
    "    info_gain_gini = overall_gini - wgini\n",
    "    info_gain_entropy = overall_entropy - wentropy\n",
    "    \n",
    "    results[feature] = {\n",
    "        'Weighted Gini': wgini,\n",
    "        'Info Gain (Gini)': info_gain_gini,\n",
    "        'Weighted Entropy': wentropy,\n",
    "        'Info Gain (Entropy)': info_gain_entropy,\n",
    "        'Details Gini': details_gini,\n",
    "        'Details Entropy': details_entropy\n",
    "    }\n",
    "    \n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"  Weighted Gini: {wgini:.5f}  |  Info Gain (Gini): {info_gain_gini:.5f}\")\n",
    "    print(f\"  Weighted Entropy: {wentropy:.5f}  |  Info Gain (Entropy): {info_gain_entropy:.5f}\\n\")\n",
    "\n",
    "# Determine the best feature based on maximum Information Gain (using Entropy, for example)\n",
    "best_feature = max(results.keys(), key=lambda x: results[x]['Info Gain (Entropy)'])\n",
    "print(\"Best Feature to split on (based on highest Info Gain from Entropy):\", best_feature)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame for a nicer display\n",
    "results_df = pd.DataFrame(results).transpose()\n",
    "print(results_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
